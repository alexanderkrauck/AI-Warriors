{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd03b92691d56bfc9d5af752bc6654e963678e4150a6c1b95c958d07e2434145127",
   "display_name": "Python 3.8.8 64-bit ('m1': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "3b92691d56bfc9d5af752bc6654e963678e4150a6c1b95c958d07e2434145127"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Train the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dataloader\n",
    "import utils.model\n",
    "from datetime import datetime\n",
    "from os.path import join\n",
    "from importlib import reload\n",
    "\n",
    "filter_timestamp = int(datetime(2021, 2, 19, 0).timestamp())\n",
    "use_user_index = join(\"indices\",\"train_user_index.parquet\")#\"train_user_index.parquet\"\n",
    "csv_data_location = join(\"data\",\"downloaded_data\")\n",
    "model_save_location = join(\"saved_models\",\"xgb_models_13_user_sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dataloader.RecSys2021TSVDataLoader(csv_data_location, use_user_index, mode=\"train\", filter_timestamp=filter_timestamp, verbose=2, remove_day_counts=True, keep_user_percent=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded Batch Nr. 1 in 17.80\n",
      "Timestamp Filtered Batch Nr. 1 in 0.57\n",
      "Did prepro part 1 of 1 in 0.62\n",
      "Did prepro part 2 of 1 in 31.76\n",
      "Did prepro part 3 of 1 in 0.14\n",
      "Merged Users of 1 in 12.06\n",
      "Extracted TE of 1 in 2.12\n",
      "Finished Batch Nr. 1 from file part-00000.tsv in 70.94s!\n",
      "CPU times: user 1min 9s, sys: 3.52 s, total: 1min 12s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = next(iter(dl))\n",
    "train_data = data[0]\n",
    "quantiles = data[1]\n",
    "labels = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 20min 27s, sys: 17.7 s, total: 20min 44s\nWall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recsysxgb = utils.model.RecSysXGB1()\n",
    "xgb_params = {'objective': 'binary:logistic', 'eval_metric':'map'}\n",
    "recsysxgb.train_in_memory(\n",
    "    train_set = train_data, \n",
    "    quantiles = quantiles, \n",
    "    targets = labels, \n",
    "    xgb_parameters = xgb_params, \n",
    "    save_dir = model_save_location\n",
    "    )"
   ]
  },
  {
   "source": [
    "## Evaluate the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_user_index = join(\"indices\",\"user_index.parquet\")#\"train_user_index.parquet\"\n",
    "recsysxgb = utils.model.RecSysXGB1(model_save_location)\n",
    "dl = dataloader.RecSys2021TSVDataLoader(csv_data_location, use_user_index, mode=\"val\", filter_timestamp=filter_timestamp, verbose=2, random_file_sampling=True, load_n_batches=1, remove_day_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded Batch Nr. 1 in 21.60\n",
      "Timestamp Filtered Batch Nr. 1 in 0.40\n",
      "Did prepro part 1 of 1 in 0.26\n",
      "Did prepro part 2 of 1 in 10.67\n",
      "Did prepro part 3 of 1 in 0.04\n",
      "Merged Users of 1 in 20.85\n",
      "Extracted TE of 1 in 3.16\n",
      "Finished Batch Nr. 1 from file part-00063.tsv in 59.10s!\n"
     ]
    }
   ],
   "source": [
    "res = recsysxgb.evaluate_validation_set(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q1_reply_rce                    : 40.43066941723738\nQ1_retweet_rce                  : 42.23354816056091\nQ1_retweet_comment_rce          : 10.557050634796173\nQ1_like_rce                     : 35.15080642986911\nQ1_reply_avg_prec               : 0.5880017132565781\nQ1_retweet_avg_prec             : 0.6506332673833364\nQ1_retweet_comment_avg_prec     : 0.4505410907293112\nQ1_like_avg_prec                : 0.8408528715639593\nQ2_reply_rce                    : 33.46047612682707\nQ2_retweet_rce                  : 37.24967154428882\nQ2_retweet_comment_rce          : 0.3776908172082427\nQ2_like_rce                     : 29.864388034567046\nQ2_reply_avg_prec               : 0.483154777305578\nQ2_retweet_avg_prec             : 0.5871992837757639\nQ2_retweet_comment_avg_prec     : 0.3466507803607606\nQ2_like_avg_prec                : 0.7956592362537639\nQ3_reply_rce                    : 31.12794796967223\nQ3_retweet_rce                  : 34.203633448816205\nQ3_retweet_comment_rce          : -4.0004203168899855\nQ3_like_rce                     : 27.337094810130235\nQ3_reply_avg_prec               : 0.45773453827068705\nQ3_retweet_avg_prec             : 0.5577185602927816\nQ3_retweet_comment_avg_prec     : 0.27254129427729484\nQ3_like_avg_prec                : 0.7756855330436296\nQ4_reply_rce                    : 25.97859985530242\nQ4_retweet_rce                  : 32.41296091421433\nQ4_retweet_comment_rce          : -8.808155494345549\nQ4_like_rce                     : 25.6746474962659\nQ4_reply_avg_prec               : 0.3899810143878341\nQ4_retweet_avg_prec             : 0.5313732470997086\nQ4_retweet_comment_avg_prec     : 0.2284852658831158\nQ4_like_avg_prec                : 0.7569673058726398\nQ5_reply_rce                    : 15.98951160473796\nQ5_retweet_rce                  : 28.543600338143836\nQ5_retweet_comment_rce          : -12.8608978473159\nQ5_like_rce                     : 22.678326889156285\nQ5_reply_avg_prec               : 0.3260139680739662\nQ5_retweet_avg_prec             : 0.4412261090578278\nQ5_retweet_comment_avg_prec     : 0.19068289788324505\nQ5_like_avg_prec                : 0.715099455897525\nTOTAL_reply_rce                 : 29.397440994755414\nTOTAL_retweet_rce               : 34.92868288120482\nTOTAL_retweet_comment_rce       : -2.9469464413094038\nTOTAL_like_rce                  : 28.141052731997718\nTOTAL_reply_avg_prec            : 0.44897720225892873\nTOTAL_retweet_avg_prec          : 0.5536300935218836\nTOTAL_retweet_comment_avg_prec  : 0.29778026582674555\nTOTAL_like_avg_prec             : 0.7768528805263035\n"
     ]
    }
   ],
   "source": [
    "for key in res:\n",
    "    print(f\"{key:32}: {res[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'TE_reply_b_B': 1185.576607681645,\n",
       " 'TE_retweet_comment_a_B': 743.8687929222223,\n",
       " 'TE_reply_a_A': 728.9023049449255,\n",
       " 'type_encoding': 498.3373325551724,\n",
       " 'TE_like_b_B': 459.2703493112501,\n",
       " 'a_follows_b': 404.63523348333337,\n",
       " 'n_like_b_B': 377.2458648152173,\n",
       " 'n_reply_b_B': 358.38123173125,\n",
       " 'TE_retweet_a_B': 327.93947554,\n",
       " 'n_like_a_A': 271.8788388888889,\n",
       " 'TE_like_b_A': 261.53769621279065,\n",
       " 'n_present_a_A': 179.29027033843744,\n",
       " 'a_follower_count': 152.18059728488234,\n",
       " 'TE_retweet_b_A': 151.9155927442857,\n",
       " 'n_reply_a_A': 151.32305655166667,\n",
       " 'n_present_b_B': 123.1579262490909,\n",
       " 'n_retweet_a_A': 108.057861,\n",
       " 'TE_retweet_b_B': 83.203886915,\n",
       " 'b_follower_count': 66.69645941666666,\n",
       " 'TE_like_a_A': 64.15599807692307,\n",
       " 'n_present_a_B': 58.981594083333334,\n",
       " 'n_retweet_b_B': 58.04761208,\n",
       " 'b_creation_delta': 50.548776246,\n",
       " 'TE_reply_a_B': 47.35697772857143,\n",
       " 'n_present_b_A': 32.950494757499996,\n",
       " 'TE_retweet_comment_b_A': 29.50127816,\n",
       " 'n_retweet_b_A': 26.04238934727273,\n",
       " 'TE_reply_b_A': 22.275766432222223,\n",
       " 'TE_retweet_a_A': 17.075756067500002,\n",
       " 'TE_retweet_comment_b_B': 12.6310272,\n",
       " 'n_retweet_a_B': 11.0541544,\n",
       " 'a_following_count': 10.814017616666668,\n",
       " 'a_creation_delta': 10.69841195,\n",
       " 'language_encoding': 10.464705945,\n",
       " 'TE_retweet_comment_a_A': 7.514288903333334,\n",
       " 'b_following_count': 7.034270295,\n",
       " 'n_like_b_A': 6.25286865,\n",
       " 'TE_like_a_B': 4.349365553333333,\n",
       " 'n_photos': 2.27819753}"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "dict(sorted(recsysxgb.clfs_[\"has_reply\"].get_score(importance_type='gain').items(), key=lambda item: item[1],reverse=True))"
   ]
  },
  {
   "source": [
    "## Try sample test run"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.model\n",
    "import utils.dataloader\n",
    "\n",
    "dl = utils.dataloader.RecSys2021TSVDataLoader(\"test\", \"user_index.parquet\", mode=\"test\", load_n_batches=-1)\n",
    "recsysxgb = utils.model.RecSysXGB1(\"xgb_models_05_submission\")\n",
    "\n",
    "recsysxgb.evaluate_test_set(testLoader = dl, output_file = \"res.csv\")"
   ]
  },
  {
   "source": [
    "## Testing Custom batch sizes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dataloader\n",
    "from utils import dataloader\n",
    "import utils.model\n",
    "from datetime import datetime\n",
    "from os.path import join\n",
    "\n",
    "filter_timestamp = None#int(datetime(2021, 2, 19, 0).timestamp())\n",
    "use_user_index = join(\"indices\",\"user_index.parquet\")#\"train_user_index.parquet\"\n",
    "csv_data_location = join(\"data\",\"test_files\")\n",
    "model_save_location = join(\"saved_models\",\"xgb_models_06_submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dataloader.RecSys2021TSVDataLoader(csv_data_location, use_user_index, mode=\"test\", filter_timestamp=filter_timestamp, load_n_batches=-1, batch_size=1000000, verbose=2, random_file_sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "just one\n",
      "1000000\n",
      "Loaded Batch Nr. 1 in 6.10\n",
      "Timestamp Filtered Batch Nr. 1 in 0.00\n",
      "Did prepro part 1 of 1 in 0.20\n",
      "Did prepro part 2 of 1 in 11.80\n",
      "Did prepro part 3 of 1 in 0.05\n",
      "Merged Users of 1 in 21.76\n",
      "Extracted TE of 1 in 3.21\n",
      "Finished Batch Nr. 1 from file part-00003.csv in 45.47s!\n",
      "just one\n",
      "1000000\n",
      "Loaded Batch Nr. 2 in 7.32\n",
      "Timestamp Filtered Batch Nr. 2 in 0.00\n",
      "Did prepro part 1 of 2 in 0.20\n",
      "Did prepro part 2 of 2 in 11.87\n",
      "Did prepro part 3 of 2 in 0.05\n",
      "Merged Users of 2 in 22.05\n",
      "Extracted TE of 2 in 3.20\n",
      "Finished Batch Nr. 2 from file part-00003.csv in 47.02s!\n",
      "just one\n",
      "1000000\n",
      "Loaded Batch Nr. 3 in 8.79\n",
      "Timestamp Filtered Batch Nr. 3 in 0.00\n",
      "Did prepro part 1 of 3 in 0.20\n",
      "Did prepro part 2 of 3 in 11.85\n",
      "Did prepro part 3 of 3 in 0.05\n",
      "Merged Users of 3 in 22.73\n",
      "Extracted TE of 3 in 3.20\n",
      "Finished Batch Nr. 3 from file part-00003.csv in 49.16s!\n",
      "more than one 1000000\n",
      "1000000\n",
      "Loaded Batch Nr. 4 in 12.99\n",
      "Timestamp Filtered Batch Nr. 4 in 0.00\n",
      "Did prepro part 1 of 4 in 0.20\n",
      "Did prepro part 2 of 4 in 11.84\n",
      "Did prepro part 3 of 4 in 0.05\n",
      "Merged Users of 4 in 20.62\n",
      "Extracted TE of 4 in 3.22\n",
      "Finished Batch Nr. 4 from file part-00002.csv in 51.52s!\n",
      "just one\n",
      "1000000\n",
      "Loaded Batch Nr. 5 in 9.31\n",
      "Timestamp Filtered Batch Nr. 5 in 0.00\n",
      "Did prepro part 1 of 5 in 0.20\n",
      "Did prepro part 2 of 5 in 11.78\n",
      "Did prepro part 3 of 5 in 0.05\n",
      "Merged Users of 5 in 21.59\n",
      "Extracted TE of 5 in 3.18\n",
      "Finished Batch Nr. 5 from file part-00002.csv in 48.45s!\n",
      "just one\n",
      "1000000\n",
      "Loaded Batch Nr. 6 in 10.75\n",
      "Timestamp Filtered Batch Nr. 6 in 0.00\n",
      "Did prepro part 1 of 6 in 0.20\n",
      "Did prepro part 2 of 6 in 11.86\n",
      "Did prepro part 3 of 6 in 0.05\n",
      "Merged Users of 6 in 21.92\n",
      "Extracted TE of 6 in 3.19\n",
      "Finished Batch Nr. 6 from file part-00002.csv in 50.29s!\n",
      "just one\n",
      "21788\n",
      "Loaded Batch Nr. 7 in 5.44\n",
      "Timestamp Filtered Batch Nr. 7 in 0.00\n",
      "Did prepro part 1 of 7 in 0.01\n",
      "Did prepro part 2 of 7 in 0.26\n",
      "Did prepro part 3 of 7 in 0.00\n",
      "Merged Users of 7 in 20.21\n",
      "Extracted TE of 7 in 3.00\n",
      "Finished Batch Nr. 7 from file part-00002.csv in 29.01s!\n"
     ]
    }
   ],
   "source": [
    "r = [a[1] for a in dl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1000000\n1000000\n1000000\n1000000\n1000000\n1000000\n21788\n"
     ]
    }
   ],
   "source": [
    "for df in r:\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.features as fe\n",
    "import utils.constants as co\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_file = pd.read_csv(\n",
    "                \"data/test_files/part-00002.csv\",\n",
    "                sep='\\x01',\n",
    "                header=None,\n",
    "                names=co.all_features,\n",
    "                dtype={k: v for k, v in co.dtypes_of_features.items() if k in co.all_features}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_file[\"medias\"] = current_file[\"medias\"].fillna(\"\")\n",
    "current_file[\"hashtags\"] = current_file[\"hashtags\"].fillna(\"\")\n",
    "current_file[\"links\"] = current_file[\"links\"].fillna(\"\")\n",
    "current_file[\"domains\"] = current_file[\"domains\"].fillna(\"\")\n",
    "current_file[\"medias\"] = current_file[\"medias\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{-0.9502129554748535, 1.0, 2.0, 3.0, 4.000000476837158, 5.0, 7.0}"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "import numpy as np\n",
    "set(np.exp(train_data[\"n_gifs\"]+ train_data[\"n_photos\"] +train_data[\"n_videos\"])-1)"
   ]
  },
  {
   "source": [
    "# Other"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}