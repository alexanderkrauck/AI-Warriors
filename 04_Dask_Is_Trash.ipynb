{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0c6b843f3af2dabb1e3fbd5873f1c8dddaea821ff1dd89faafeae1498b4512a80",
   "display_name": "Python 3.8.8 64-bit ('m3': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "from os.path import join\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [\"bert_base_multilingual_cased_tokens\",\n",
    "                \"hashtags\",\n",
    "                \"tweet_id\",\n",
    "                \"medias\",\n",
    "                \"links\",\n",
    "                \"domains\",\n",
    "                \"type\",\n",
    "                \"language\",\n",
    "                \"timestamp\",\n",
    "                \"a_user_id\",\n",
    "                \"a_follower_count\",\n",
    "                \"a_following_count\",\n",
    "                \"a_is_verified\",\n",
    "                \"a_account_creation\",\n",
    "                \"b_user_id\",\n",
    "                \"b_follower_count\",\n",
    "                \"b_following_count\",\n",
    "                \"b_is_verified\",\n",
    "                \"b_account_creation\",\n",
    "                \"a_follows_b\"]\n",
    "\n",
    "all_labels = [\"reply\",\n",
    "              \"retweet\",\n",
    "              \"retweet_comment\",\n",
    "              \"like\"]\n",
    "\n",
    "dtypes_of_features = {\n",
    "    \"bert_base_multilingual_cased_tokens\": str,\n",
    "    \"hashtags\": str,\n",
    "    \"tweet_id\": str,\n",
    "    \"medias\": str,\n",
    "    \"links\": str,\n",
    "    \"domains\": str,\n",
    "    \"type\": str,\n",
    "    \"language\": str,\n",
    "    \"timestamp\": np.uint32,\n",
    "    \"a_user_id\": str,\n",
    "    \"a_follower_count\": np.uint32,\n",
    "    \"a_following_count\": np.uint32,\n",
    "    \"a_is_verified\": bool,\n",
    "    \"a_account_creation\": np.uint32,\n",
    "    \"b_user_id\": str,\n",
    "    \"b_follower_count\": np.uint32,\n",
    "    \"b_following_count\": np.uint32,\n",
    "    \"b_is_verified\": bool,\n",
    "    \"b_account_creation\": np.uint32,\n",
    "    \"a_follows_b\": bool,\n",
    "    \"reply\": np.uint32,\n",
    "    \"retweet\": np.uint32,\n",
    "    \"retweet_comment\": np.uint32,\n",
    "    \"like\": np.uint32\n",
    "}\n",
    "all_columns = all_features + all_labels\n",
    "\n",
    "user_centric_cols = [\"a_user_id\",\n",
    "                \"a_follower_count\",\n",
    "                \"a_following_count\",\n",
    "                \"a_is_verified\",\n",
    "                \"a_account_creation\",\n",
    "                \"b_user_id\",\n",
    "                \"b_follower_count\",\n",
    "                \"b_following_count\",\n",
    "                \"b_is_verified\",\n",
    "                \"b_account_creation\",\n",
    "                \"reply\",\n",
    "                \"retweet\",\n",
    "                \"retweet_comment\",\n",
    "                \"like\",\n",
    "                \"timestamp\"]\n",
    "\n",
    "training_csv = \"training_files\"\n",
    "temp_csv = \"temp_user_mappings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Merging part-00000.csv...Wall time: 43.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "md = 2**64\n",
    "\n",
    "\n",
    "for file in os.listdir(training_csv):\n",
    "    if \".csv\" not in file and \".tsv\" not in file:\n",
    "        continue\n",
    "    print(f\"\\rReading CSV {file}...\", end=\"\")\n",
    "    df = pd.read_csv(join(training_csv, file), sep='\\x01', header=None, names=all_columns, \n",
    "        dtype={k: v for k, v in dtypes_of_features.items() if k in all_features}, usecols=user_centric_cols)\n",
    "    \n",
    "    print(f\"\\rCreating User Maps for {file}...\", end=\"\")\n",
    "    df[\"a_user_id\"] = df[\"a_user_id\"].apply(lambda x: int(x, base=16)%md).astype(np.uint64)\n",
    "    df[\"b_user_id\"] = df[\"b_user_id\"].apply(lambda x: int(x, base=16)%md).astype(np.uint64)\n",
    "\n",
    "    user_dfs = []\n",
    "    cols = [\"user_id\", \"follower_count\", \"following_count\", \"verified\", \"account_creation\", \"timestamp\", \"action_type\"]\n",
    "\n",
    "\n",
    "    df_a = df[[\"a_user_id\", \"a_follower_count\", \"a_following_count\", \"a_is_verified\", \"a_account_creation\",\"timestamp\"]].copy()\n",
    "    df_a.loc[:,\"action_type\"] = 0\n",
    "    df_a.columns = cols\n",
    "    df_a[\"day\"] = df_a[\"timestamp\"].apply(lambda x: datetime.fromtimestamp(x).day).astype(np.uint8)\n",
    "    user_dfs.append(df_a)\n",
    "\n",
    "    df_b = df[[\"b_user_id\", \"b_follower_count\", \"b_following_count\", \"b_is_verified\", \"b_account_creation\", \"timestamp\"]].copy()\n",
    "    df_b.loc[:,\"action_type\"] = 1\n",
    "    df_b.columns = cols\n",
    "    df_b[\"day\"] = df_b[\"timestamp\"].apply(lambda x: datetime.fromtimestamp(x).day).astype(np.uint8)\n",
    "    user_dfs.append(df_b)\n",
    "\n",
    "    for idx, col in enumerate(['reply',\"retweet\",\"retweet_comment\",\"like\"]):\n",
    "        temp_df = df[[\"b_user_id\", \"b_follower_count\", \"b_following_count\", \"b_is_verified\", \"b_account_creation\", col]].copy()\n",
    "        temp_df = temp_df.dropna(subset=[col])\n",
    "        temp_df.loc[:,\"action_type\"] = idx + 2\n",
    "        temp_df.columns = cols\n",
    "        temp_df[\"day\"] = temp_df[\"timestamp\"].apply(lambda x: datetime.fromtimestamp(x).day).astype(np.uint8)\n",
    "        user_dfs.append(temp_df)\n",
    "\n",
    "    user_df = pd.concat(user_dfs)\n",
    "\n",
    "    gb = user_df.groupby(\"user_id\")\n",
    "    gb_cnt = user_df.groupby([\"user_id\", \"action_type\"])\n",
    "    gb_day_cnt = user_df.groupby([\"user_id\", \"day\"])\n",
    "\n",
    "    print(f\"\\rExtracting Features for {file}...\", end=\"\")\n",
    "\n",
    "\n",
    "    res = gb.agg({\n",
    "        'follower_count': \"first\", \n",
    "        'following_count':'first', \n",
    "        'verified':'first', \n",
    "        'account_creation': \"first\"\n",
    "        })\n",
    "\n",
    "    print(f\"\\rExtracting Counts for {file}...\", end=\"\")\n",
    "\n",
    "    cnt_res = gb_cnt.size().unstack(fill_value=0)\n",
    "    day_cnt = gb_day_cnt.size().unstack(fill_value=0)\n",
    "    cnt_res.columns =  [\"n_present_a\",\"n_present_b\",\"n_reply\",\"n_retweet\",\"n_retweet_comment\",\"n_like\"]\n",
    "    day_cnt.columns = [\"n_day_\"+str(a) for a in day_cnt.columns]\n",
    "\n",
    "    print(f\"\\rMerging {file}...\", end=\"\")\n",
    "\n",
    "    user_df = pd.merge(res, cnt_res, how='inner', left_index=True, right_index=True)\n",
    "    user_df = pd.merge(user_df, day_cnt, how=\"inner\", left_index=True, right_index=True)\n",
    "    print(f\"\\rWriting File {file}...\", end=\"\")\n",
    "    user_df.to_parquet(join(temp_csv, file.split(\".\")[0]+\".parquet\"))\n",
    "    gc.collect()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Collecting overlaps of part-00080.parquet...\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "big_user_df = None\n",
    "for file in os.listdir(temp_csv):\n",
    "    if \".parquet\" not in file:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\rReading temp file {file}...\", end=\"\")\n",
    "    if big_user_df is None:\n",
    "        big_user_df = pd.read_parquet(join(temp_csv,file))\n",
    "        continue\n",
    "\n",
    "    user_df = pd.read_parquet(join(temp_csv,file))\n",
    "    user_df.columns = [\"next_\"+a for a in user_df.columns]\n",
    "\n",
    "    print(f\"\\r Collecting overlaps of {file}...\", end=\"\")\n",
    "    res = pd.merge(big_user_df, user_df, how=\"outer\", left_index=True, right_index=True, indicator=True)\n",
    "\n",
    "    from_left = big_user_df.loc[res.query('_merge==\"left_only\"').index]\n",
    "    from_right = user_df.loc[res.query('_merge==\"right_only\"').index]\n",
    "    both_extracted = res.query('_merge==\"both\"')\n",
    "\n",
    "    print(f\"\\r Accumulating Features {file}...\", end=\"\")\n",
    "    for col in both_extracted.columns:\n",
    "        if col.startswith(\"n\"):\n",
    "            both_extracted[col] = both_extracted[col]  +  both_extracted[\"next_\"+col] \n",
    "\n",
    "\n",
    "    from_right.columns = [a[5:] for a in from_right.columns]\n",
    "    both_extracted = both_extracted[from_left.columns]\n",
    "\n",
    "    print(f\"\\r Final Concat with sort {file}...\", end=\"\")\n",
    "    big_user_df = pd.concat([from_left, from_right, both_extracted])\n",
    "    big_user_df = big_user_df.sort_index()\n",
    "    gc.collect()\n",
    "    break\n",
    "#big_user_df.to_csv(\"user_index.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['follower_count', 'following_count', 'verified', 'account_creation',\n",
       "       'n_present_a', 'n_present_b', 'n_reply', 'n_retweet',\n",
       "       'n_retweet_comment', 'n_like', 'n_day_4', 'n_day_5', 'n_day_6',\n",
       "       'n_day_7', 'n_day_8', 'n_day_9', 'n_day_10', 'n_day_11', 'n_day_12',\n",
       "       'n_day_13', 'n_day_14', 'n_day_15', 'n_day_16', 'n_day_17', 'n_day_18',\n",
       "       'n_day_19', 'n_day_20', 'n_day_21', 'n_day_22', 'n_day_23', 'n_day_24',\n",
       "       'n_day_25'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "user_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}